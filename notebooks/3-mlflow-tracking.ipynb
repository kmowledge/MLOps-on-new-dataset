{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f8a0c1",
   "metadata": {},
   "source": [
    "## MLflow Integration for Alcoholism Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path and import required modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from DSML.config import RAW_DATA_DIR, categorical, target\n",
    "from DSML.preproc import get_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace266e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track git information for experiment versioning\n",
    "from DSML.helpers import get_active_branch_name, get_git_commit_hash\n",
    "\n",
    "branch = get_active_branch_name(\"..\")\n",
    "commit = get_git_commit_hash()\n",
    "print(f\"Current branch: {branch}\")\n",
    "print(f\"Current commit: {commit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "df = get_raw_data()\n",
    "\n",
    "# Create target variable\n",
    "y = df.pop('Alcoholic')\n",
    "X = df\n",
    "\n",
    "# Get categorical column indices for CatBoost\n",
    "categorical_indices = [X.columns.get_loc(col) for col in categorical if col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59796d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow tracking\n",
    "import mlflow\n",
    "from DSML.train import run_hyperopt, get_or_create_experiment\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create or get experiment\n",
    "experiment_id = get_or_create_experiment(\"alcohol_hyperparam_tuning\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_params_path = run_hyperopt(X, y, categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "import joblib\n",
    "from DSML.train import train_cv\n",
    "\n",
    "params = joblib.load(best_params_path)\n",
    "print(\"Best parameters:\", params)\n",
    "\n",
    "n_folds = 5\n",
    "cv_output_path = train_cv(X, y, categorical_indices, params, n=n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed789fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-validation results\n",
    "import pandas as pd\n",
    "from DSML.train import plot_error_scatter\n",
    "\n",
    "cv_results = pd.read_csv(cv_output_path)\n",
    "\n",
    "# Plot F1 scores\n",
    "plot_error_scatter(\n",
    "    df_plot=cv_results,\n",
    "    name=\"Mean F1 Score\",\n",
    "    title=\"Cross-Validation (N=5) Mean F1 score with Error Bands\",\n",
    "    xtitle=\"Training Steps\",\n",
    "    ytitle=\"Performance Score\",\n",
    "    yaxis_range=[0.5, 1]\n",
    ")\n",
    "\n",
    "# Plot logloss\n",
    "plot_error_scatter(\n",
    "    df_plot=cv_results,\n",
    "    x=\"iterations\",\n",
    "    y=\"test-Logloss-mean\",\n",
    "    err=\"test-Logloss-std\",\n",
    "    name=\"Mean logloss\",\n",
    "    title=\"Cross-Validation (N=5) Mean Logloss with Error Bands\",\n",
    "    xtitle=\"Training Steps\",\n",
    "    ytitle=\"Logloss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with MLflow tracking\n",
    "from DSML.train import train\n",
    "\n",
    "experiment_id = get_or_create_experiment(\"alcohol_full_training\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "model_path, model_params_path = train(X, y, categorical_indices, params, cv_results=cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from MLflow and make predictions\n",
    "import json\n",
    "from DSML.predict import predict\n",
    "from mlflow.client import MlflowClient\n",
    "\n",
    "client = MlflowClient(mlflow.get_tracking_uri())\n",
    "\n",
    "# Get latest model version\n",
    "model_info = client.get_latest_versions('alcohol-class')[0]\n",
    "\n",
    "# Get model metadata\n",
    "run_data_dict = client.get_run(model_info.run_id).data.to_dictionary()\n",
    "run = client.get_run(model_info.run_id)\n",
    "log_model_meta = json.loads(run.data.tags['mlflow.log-model.history'])\n",
    "\n",
    "# Load and use model\n",
    "_, artifact_folder = os.path.split(model_info.source)\n",
    "model_uri = f\"runs:/{model_info.run_id}/{artifact_folder}\"\n",
    "loaded_model = mlflow.catboost.load_model(model_uri)\n",
    "\n",
    "# Make predictions\n",
    "params = run_data_dict[\"params\"]\n",
    "params[\"feature_columns\"] = [inp[\"name\"] for inp in json.loads(log_model_meta[0]['signature']['inputs'])]\n",
    "preds_path = predict(loaded_model, X, params)\n",
    "print(f\"Predictions saved to: {preds_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare champion and challenger models if available\n",
    "from DSML.resolve import get_model_by_alias\n",
    "\n",
    "champ_model = get_model_by_alias(client, alias=\"champion\")\n",
    "chall_model = get_model_by_alias(client, alias=\"challenger\")\n",
    "\n",
    "if champ_model and chall_model:\n",
    "    print(\"Champion model version:\", champ_model.version)\n",
    "    print(\"Challenger model version:\", chall_model.version)\n",
    "else:\n",
    "    print(\"No champion/challenger models set yet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
