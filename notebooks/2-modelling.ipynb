{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72766c1c",
   "metadata": {},
   "source": [
    "## Version 2 - Refactored Implementation\n",
    "We need to refactor this solution to be more maintainable and production-ready. We'll:\n",
    "1. Move code into proper modules\n",
    "2. Add MLflow tracking\n",
    "3. Implement proper code quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420a972",
   "metadata": {},
   "source": [
    "Add autoreload since we are now modifying scripts in other folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727483ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-26 20:17:33.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDSML.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/gabrielluizone/high-school-alcoholism-and-academic-performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-26 20:17:34.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRAW_DATA_DIR is: D:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\dataset\\raw\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from DSML.config import DATASET, PROCESSED_DATA_DIR, RAW_DATA_DIR\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from loguru import logger\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "download_folder = Path(RAW_DATA_DIR)\n",
    "api.dataset_download_files(DATASET, path=str(download_folder), unzip=True)\n",
    "logger.info(f\"RAW_DATA_DIR is: {RAW_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4eddb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825a9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from DSML.preproc import get_raw_data\n",
    "from DSML.config import RAW_DATA_DIR, target, categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf9b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Check Python executable path\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc55ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDSML\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_hyperopt, get_or_create_experiment\n\u001b[32m      4\u001b[39m experiment_id = get_or_create_experiment(\u001b[33m\"\u001b[39m\u001b[33malcohol_hyperparam_tuning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m mlflow.set_experiment(experiment_id=experiment_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\DSML\\train.py:24\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDSML\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     FIGURES_DIR,\n\u001b[32m     17\u001b[39m     MODEL_NAME,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     target,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDSML\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_git_commit_hash\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnml\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# comment to trigger workflow ver6\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_hyperopt\u001b[39m(X_train:pd.DataFrame, y_train:pd.DataFrame, categorical_indices:\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], test_size:\u001b[38;5;28mfloat\u001b[39m=\u001b[32m0.25\u001b[39m, n_trials:\u001b[38;5;28mint\u001b[39m=\u001b[32m20\u001b[39m, overwrite:\u001b[38;5;28mbool\u001b[39m=\u001b[38;5;28;01mFalse\u001b[39;00m)->\u001b[38;5;28mstr\u001b[39m|Path:  \u001b[38;5;66;03m# noqa: PLR0913\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Lib\\site-packages\\nannyml\\__init__.py:64\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdrift\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     57\u001b[39m     AlertCountRanker,\n\u001b[32m     58\u001b[39m     CorrelationRanker,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     UnivariateDriftCalculator,\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChunkerException, InvalidArgumentsException, MissingMetadataException\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PickleFileWriter, RawFilesWriter\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mperformance_calculation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PerformanceCalculator\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mperformance_estimation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CBPE, DLE\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Lib\\site-packages\\nannyml\\io\\__init__.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_module\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader, Writer, WriterFactory\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileReader\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileWriter\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpickle_file_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PickleFileWriter\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Lib\\site-packages\\nannyml\\io\\file_reader.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PurePosixPath\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InvalidArgumentsException\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Lib\\site-packages\\fsspec\\__init__.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m available_compressions\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_fs_token_paths, \u001b[38;5;28mopen\u001b[39m, open_files, open_local, url_to_fs\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FSTimeoutError\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sdev\\wwsi\\arisa\\MLOps-on-new-dataset\\.venv\\Lib\\site-packages\\fsspec\\compression.py:100\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlzmaffi\u001b[39;00m\n\u001b[32m    102\u001b[39m     register_compression(\u001b[33m\"\u001b[39m\u001b[33mlzma\u001b[39m\u001b[33m\"\u001b[39m, lzmaffi.LZMAFile, \u001b[33m\"\u001b[39m\u001b[33mlzma\u001b[39m\u001b[33m\"\u001b[39m, force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    103\u001b[39m     register_compression(\u001b[33m\"\u001b[39m\u001b[33mxz\u001b[39m\u001b[33m\"\u001b[39m, lzmaffi.LZMAFile, \u001b[33m\"\u001b[39m\u001b[33mxz\u001b[39m\u001b[33m\"\u001b[39m, force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1138\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1078\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1507\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1479\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1615\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from DSML.train import run_hyperopt, get_or_create_experiment\n",
    "\n",
    "experiment_id = get_or_create_experiment(\"alcohol_hyperparam_tuning\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_train = get_raw_data()\n",
    "\n",
    "# Create target variable and split features\n",
    "y = df_train.pop('Alcoholic')\n",
    "X = df_train\n",
    "\n",
    "categorical_indices = [X.columns.get_loc(col) for col in categorical if col in X.columns]\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_params_path = run_hyperopt(X, y, categorical_indices, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e69634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DSML.train import train_cv\n",
    "import joblib\n",
    "\n",
    "params = joblib.load(best_params_path)\n",
    "print(\"Best parameters:\", params)\n",
    "\n",
    "n_folds = 5\n",
    "cv_output_path = train_cv(X, y, categorical_indices, params, n=n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ee4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from DSML.train import plot_error_scatter\n",
    "\n",
    "cv_results = pd.read_csv(cv_output_path)\n",
    "\n",
    "# Plot F1 score\n",
    "plot_error_scatter(\n",
    "    df_plot=cv_results,\n",
    "    name=\"Mean F1 Score\",\n",
    "    title=\"Cross-Validation (N=5) Mean F1 score with Error Bands\",\n",
    "    xtitle=\"Training Steps\",\n",
    "    ytitle=\"Performance Score\",\n",
    "    yaxis_range=[0.5, 1]\n",
    ")\n",
    "\n",
    "# Plot logloss\n",
    "plot_error_scatter(\n",
    "    df_plot=cv_results,\n",
    "    x=\"iterations\",\n",
    "    y=\"test-Logloss-mean\",\n",
    "    err=\"test-Logloss-std\", \n",
    "    name=\"Mean logloss\",\n",
    "    title=\"Cross-Validation (N=5) Mean Logloss with Error Bands\",\n",
    "    xtitle=\"Training Steps\",\n",
    "    ytitle=\"Logloss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48083354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "from DSML.train import train\n",
    "model_path, model_params_path = train(X, y, categorical_indices, params)\n",
    "\n",
    "# Generate SHAP plots\n",
    "from DSML.predict import explain_predictions\n",
    "explain_predictions(model_path, X)\n",
    "\n",
    "# Make predictions\n",
    "from DSML.predict import predict_and_save\n",
    "predictions_path = predict_and_save(model_path, X, df_ids)\n",
    "print(f\"Predictions saved to: {predictions_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
