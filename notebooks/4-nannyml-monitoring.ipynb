{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a2b24e",
   "metadata": {},
   "source": [
    "## Data Drift Monitoring with NannyML\n",
    "Monitor model performance and data drift for the alcoholism prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80202042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from DSML.config import RAW_DATA_DIR, categorical, target\n",
    "from DSML.preproc import get_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad675bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original dataset\n",
    "df = get_raw_data()\n",
    "\n",
    "# Split target and features\n",
    "y = df.pop('Alcoholic')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4837e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with same parameters as before\n",
    "import joblib\n",
    "from DSML.train import run_hyperopt\n",
    "categorical_indices = [X.columns.get_loc(col) for col in categorical if col in X.columns]\n",
    "best_params_path = run_hyperopt(X, y, categorical_indices)\n",
    "params = joblib.load(best_params_path)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(**params, verbose=True)\n",
    "model.fit(X, y, cat_features=categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare reference data for NannyML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reference_df = X.copy()\n",
    "reference_df[\"prediction\"] = model.predict(X)\n",
    "reference_df[\"predicted_probability\"] = [p[1] for p in model.predict_proba(X)]\n",
    "reference_df[target] = y\n",
    "\n",
    "# Get column names for drift calculation\n",
    "feature_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NannyML calculators\n",
    "import nannyml as nml\n",
    "\n",
    "# Set chunk size for drift calculation\n",
    "chunk_size = 50\n",
    "\n",
    "# Initialize univariate drift calculator\n",
    "udc = nml.UnivariateDriftCalculator(\n",
    "    column_names=feature_columns,\n",
    "    chunk_size=chunk_size,\n",
    ")\n",
    "udc.fit(X)\n",
    "\n",
    "# Initialize performance estimator\n",
    "estimator = nml.CBPE(\n",
    "    problem_type=\"classification_binary\",\n",
    "    y_pred_proba=\"predicted_probability\",\n",
    "    y_pred=\"prediction\",\n",
    "    y_true=target,\n",
    "    metrics=[\"roc_auc\"],\n",
    "    chunk_size=chunk_size,\n",
    ")\n",
    "estimator = estimator.fit(reference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis function\n",
    "def analyze_drift(estimator, udc, analysis_df, feature_cols):\n",
    "    \"\"\"Analyze data drift and model performance\"\"\"\n",
    "    analysis_df = analysis_df.copy()\n",
    "    \n",
    "    # Get predictions for analysis set\n",
    "    analysis_df[\"prediction\"] = model.predict(analysis_df[feature_cols])\n",
    "    analysis_df[\"predicted_probability\"] = [p[1] for p in model.predict_proba(analysis_df[feature_cols])]\n",
    "    \n",
    "    # Estimate performance\n",
    "    estimated_performance = estimator.estimate(analysis_df)\n",
    "    performance_plot = estimated_performance.plot()\n",
    "    performance_plot.show()\n",
    "\n",
    "    # Calculate drift\n",
    "    univariate_drift = udc.calculate(analysis_df[feature_cols])\n",
    "    \n",
    "    # Rank features by alert count\n",
    "    alert_ranker = nml.AlertCountRanker()\n",
    "    alert_ranking = alert_ranker.rank(univariate_drift)\n",
    "    display(alert_ranking)\n",
    "\n",
    "    # Plot drift for each feature\n",
    "    for col in feature_cols:\n",
    "        try:\n",
    "            univariate_drift.filter(column_names=[col]).plot().show()\n",
    "            univariate_drift.filter(period=\"analysis\", column_names=[col]).plot(kind='distribution').show()\n",
    "        except:\n",
    "            print(f\"Failed to plot drift analysis for {col}\")\n",
    "            \n",
    "    return univariate_drift, estimated_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data with drift for testing\n",
    "import numpy as np\n",
    "\n",
    "n_samples = 100\n",
    "synthetic_data = X.copy().iloc[:n_samples]\n",
    "\n",
    "# Introduce drift in some numeric columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    synthetic_data[col] = synthetic_data[col] * np.random.uniform(0.8, 1.2, size=n_samples)\n",
    "\n",
    "# Analyze drift in synthetic data\n",
    "drift_results, perf_results = analyze_drift(estimator, udc, synthetic_data, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15532a8",
   "metadata": {},
   "source": [
    "The above analysis helps identify:\n",
    "1. Which features are experiencing drift\n",
    "2. How the model performance is affected\n",
    "3. Which features contribute most to performance degradation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
